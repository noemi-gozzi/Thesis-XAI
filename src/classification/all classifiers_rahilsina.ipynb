{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the library versions this code employed is mentioned in comments, if something doesn't work change your package versions\n",
    "# to these ones, especially sklearn\n",
    "\n",
    "import pandas as pd # version 0.24.2\n",
    "import numpy as np #version 1.16.4\n",
    "import random\n",
    "import matplotlib.pyplot as plt #matplotlib version 3.1.0\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns #version 0.9.0\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__) # this code works with sklearn 0.21.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1\n",
      "Round1 (2755, 152)\n",
      "Round2 (2880, 152)\n",
      "round3 (2588, 152)\n"
     ]
    }
   ],
   "source": [
    "# this version of database had 15 features for each channel (in total 10 channel) making 150 features\n",
    "# for each subject we have 3 seperate databases for 3 rounds\n",
    "N_Subj = 11 # 11 subjects\n",
    "df_r1= [0] * N_Subj # dataframe for round1 for all subjects\n",
    "df_r2= [0] * N_Subj # dataframe for round2 for all subjects\n",
    "df_r3= [0] * N_Subj # dataframe for round3 for all subjects\n",
    "\n",
    "# making a column name for dataframe\n",
    "# the database is organized in the way that first feature of all 10 channels are at the beginning, then the second feature for all channels and so on\n",
    "cl_names= []\n",
    "for i in range(1,11):\n",
    "    cl_names.append('MAV'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('ZC'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('SSC'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('WL'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('HP_A'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('HP_M'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('HP_C'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('SE'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('CCI_'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('CCII_'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('CCIII_'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('CCIV_'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('RMS'+str(i))    \n",
    "for i in range(1,11):\n",
    "    cl_names.append('IEMG'+str(i))\n",
    "for i in range(1,11):\n",
    "    cl_names.append('SKEW'+str(i))\n",
    "    \n",
    "cl_names.append('class') #column dedicated to show which class of movement this sample belongs to\n",
    "cl_names.append('move') #column dedicated to show which number of movement (out of 40 in each round) this sample belongs to\n",
    "\n",
    "#loading sepearte databases for each round and subject\n",
    "for i in range(0,N_Subj):\n",
    "    df_r1[i] = pd.read_csv('database_v2_sbj'+str(i+1)+'_s1_WL512_S128_r1.csv')\n",
    "    df_r1[i].columns=cl_names\n",
    "    \n",
    "    df_r2[i] = pd.read_csv('database_v2_sbj'+str(i+1)+'_s1_WL512_S128_r2.csv')\n",
    "    df_r2[i].columns=cl_names\n",
    "    \n",
    "    df_r3[i] = pd.read_csv('database_v2_sbj'+str(i+1)+'_s1_WL512_S128_r3.csv')\n",
    "    df_r3[i].columns=cl_names\n",
    "\n",
    "print(\"Subject1\")\n",
    "print(\"Round1\",np.shape(df_r1[0]))\n",
    "print(\"Round2\",np.shape(df_r2[0]))\n",
    "print(\"round3\",np.shape(df_r3[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAV1      float64\n",
      "MAV2      float64\n",
      "MAV3      float64\n",
      "MAV4      float64\n",
      "MAV5      float64\n",
      "MAV6      float64\n",
      "MAV7      float64\n",
      "MAV8      float64\n",
      "MAV9      float64\n",
      "MAV10     float64\n",
      "ZC1         int64\n",
      "ZC2         int64\n",
      "ZC3         int64\n",
      "ZC4         int64\n",
      "ZC5         int64\n",
      "ZC6         int64\n",
      "ZC7         int64\n",
      "ZC8         int64\n",
      "ZC9         int64\n",
      "ZC10        int64\n",
      "SSC1        int64\n",
      "SSC2        int64\n",
      "SSC3        int64\n",
      "SSC4        int64\n",
      "SSC5        int64\n",
      "SSC6        int64\n",
      "SSC7        int64\n",
      "SSC8        int64\n",
      "SSC9        int64\n",
      "SSC10       int64\n",
      "           ...   \n",
      "RMS3      float64\n",
      "RMS4      float64\n",
      "RMS5      float64\n",
      "RMS6      float64\n",
      "RMS7      float64\n",
      "RMS8      float64\n",
      "RMS9      float64\n",
      "RMS10     float64\n",
      "IEMG1     float64\n",
      "IEMG2     float64\n",
      "IEMG3     float64\n",
      "IEMG4     float64\n",
      "IEMG5     float64\n",
      "IEMG6     float64\n",
      "IEMG7     float64\n",
      "IEMG8     float64\n",
      "IEMG9     float64\n",
      "IEMG10    float64\n",
      "SKEW1     float64\n",
      "SKEW2     float64\n",
      "SKEW3     float64\n",
      "SKEW4     float64\n",
      "SKEW5     float64\n",
      "SKEW6     float64\n",
      "SKEW7     float64\n",
      "SKEW8     float64\n",
      "SKEW9     float64\n",
      "SKEW10    float64\n",
      "class       int64\n",
      "move        int64\n",
      "Length: 152, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAV1</th>\n",
       "      <th>MAV2</th>\n",
       "      <th>MAV3</th>\n",
       "      <th>MAV4</th>\n",
       "      <th>MAV5</th>\n",
       "      <th>MAV6</th>\n",
       "      <th>MAV7</th>\n",
       "      <th>MAV8</th>\n",
       "      <th>MAV9</th>\n",
       "      <th>MAV10</th>\n",
       "      <th>...</th>\n",
       "      <th>SKEW3</th>\n",
       "      <th>SKEW4</th>\n",
       "      <th>SKEW5</th>\n",
       "      <th>SKEW6</th>\n",
       "      <th>SKEW7</th>\n",
       "      <th>SKEW8</th>\n",
       "      <th>SKEW9</th>\n",
       "      <th>SKEW10</th>\n",
       "      <th>class</th>\n",
       "      <th>move</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011440</td>\n",
       "      <td>0.007049</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.040629</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.017786</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>0.029614</td>\n",
       "      <td>0.022596</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318860</td>\n",
       "      <td>0.23952</td>\n",
       "      <td>0.039047</td>\n",
       "      <td>-0.637670</td>\n",
       "      <td>-1.401700</td>\n",
       "      <td>-0.536760</td>\n",
       "      <td>1.109600</td>\n",
       "      <td>0.280630</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047077</td>\n",
       "      <td>0.034412</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>0.095069</td>\n",
       "      <td>0.094247</td>\n",
       "      <td>0.144480</td>\n",
       "      <td>0.051746</td>\n",
       "      <td>0.060704</td>\n",
       "      <td>0.088419</td>\n",
       "      <td>0.061936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070388</td>\n",
       "      <td>0.34692</td>\n",
       "      <td>0.213570</td>\n",
       "      <td>0.512390</td>\n",
       "      <td>-0.089661</td>\n",
       "      <td>-0.120520</td>\n",
       "      <td>0.109120</td>\n",
       "      <td>0.409140</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032606</td>\n",
       "      <td>0.015454</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.041959</td>\n",
       "      <td>0.095004</td>\n",
       "      <td>0.046755</td>\n",
       "      <td>0.033878</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.101260</td>\n",
       "      <td>0.035861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118980</td>\n",
       "      <td>0.20484</td>\n",
       "      <td>0.068442</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.327350</td>\n",
       "      <td>-0.110150</td>\n",
       "      <td>-0.027281</td>\n",
       "      <td>0.118570</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015377</td>\n",
       "      <td>0.020118</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>0.020248</td>\n",
       "      <td>0.051079</td>\n",
       "      <td>0.016831</td>\n",
       "      <td>0.011195</td>\n",
       "      <td>0.016046</td>\n",
       "      <td>0.027189</td>\n",
       "      <td>0.014337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047136</td>\n",
       "      <td>0.14082</td>\n",
       "      <td>-0.371070</td>\n",
       "      <td>-0.108130</td>\n",
       "      <td>0.069448</td>\n",
       "      <td>-0.099661</td>\n",
       "      <td>-0.346300</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012313</td>\n",
       "      <td>0.014122</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>0.087738</td>\n",
       "      <td>0.126720</td>\n",
       "      <td>0.032815</td>\n",
       "      <td>0.010385</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>0.224500</td>\n",
       "      <td>0.018224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035113</td>\n",
       "      <td>-0.42522</td>\n",
       "      <td>0.069521</td>\n",
       "      <td>0.263290</td>\n",
       "      <td>0.267010</td>\n",
       "      <td>-0.135760</td>\n",
       "      <td>-0.026827</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.024255</td>\n",
       "      <td>0.031359</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>0.034794</td>\n",
       "      <td>0.066356</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>0.018291</td>\n",
       "      <td>0.029561</td>\n",
       "      <td>0.038092</td>\n",
       "      <td>0.019897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419130</td>\n",
       "      <td>0.50191</td>\n",
       "      <td>-0.670990</td>\n",
       "      <td>0.127950</td>\n",
       "      <td>-0.144300</td>\n",
       "      <td>-0.395270</td>\n",
       "      <td>0.142920</td>\n",
       "      <td>-0.141420</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.042481</td>\n",
       "      <td>0.097330</td>\n",
       "      <td>0.020678</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.120970</td>\n",
       "      <td>0.014435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.10333</td>\n",
       "      <td>0.048375</td>\n",
       "      <td>-0.349530</td>\n",
       "      <td>-0.592230</td>\n",
       "      <td>-0.122360</td>\n",
       "      <td>0.261010</td>\n",
       "      <td>0.061718</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.054127</td>\n",
       "      <td>0.040739</td>\n",
       "      <td>0.028140</td>\n",
       "      <td>0.145410</td>\n",
       "      <td>0.091580</td>\n",
       "      <td>0.212510</td>\n",
       "      <td>0.078169</td>\n",
       "      <td>0.078086</td>\n",
       "      <td>0.105670</td>\n",
       "      <td>0.083278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423170</td>\n",
       "      <td>0.17383</td>\n",
       "      <td>0.376420</td>\n",
       "      <td>0.072196</td>\n",
       "      <td>-0.787140</td>\n",
       "      <td>0.065149</td>\n",
       "      <td>-0.273930</td>\n",
       "      <td>0.342480</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.022851</td>\n",
       "      <td>0.030370</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>0.050820</td>\n",
       "      <td>0.069157</td>\n",
       "      <td>0.017366</td>\n",
       "      <td>0.017194</td>\n",
       "      <td>0.037149</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147890</td>\n",
       "      <td>0.29822</td>\n",
       "      <td>-0.105220</td>\n",
       "      <td>0.072432</td>\n",
       "      <td>-0.023623</td>\n",
       "      <td>-0.159720</td>\n",
       "      <td>0.139350</td>\n",
       "      <td>-0.192820</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.018317</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.008729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028861</td>\n",
       "      <td>-0.10196</td>\n",
       "      <td>-0.334590</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.274650</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>-0.106770</td>\n",
       "      <td>0.019649</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MAV1      MAV2      MAV3      MAV4      MAV5      MAV6      MAV7  \\\n",
       "0  0.011440  0.007049  0.007343  0.040629  0.012729  0.017786  0.013964   \n",
       "1  0.047077  0.034412  0.019688  0.095069  0.094247  0.144480  0.051746   \n",
       "2  0.032606  0.015454  0.011722  0.041959  0.095004  0.046755  0.033878   \n",
       "3  0.015377  0.020118  0.009892  0.020248  0.051079  0.016831  0.011195   \n",
       "4  0.012313  0.014122  0.019198  0.087738  0.126720  0.032815  0.010385   \n",
       "5  0.024255  0.031359  0.013659  0.034794  0.066356  0.018987  0.018291   \n",
       "6  0.007872  0.007103  0.009197  0.042481  0.097330  0.020678  0.008299   \n",
       "7  0.054127  0.040739  0.028140  0.145410  0.091580  0.212510  0.078169   \n",
       "8  0.022851  0.030370  0.016029  0.050820  0.069157  0.017366  0.017194   \n",
       "9  0.006650  0.004515  0.004592  0.006869  0.024242  0.018317  0.009985   \n",
       "\n",
       "       MAV8      MAV9     MAV10  ...     SKEW3    SKEW4     SKEW5     SKEW6  \\\n",
       "0  0.029614  0.022596  0.009105  ...  0.318860  0.23952  0.039047 -0.637670   \n",
       "1  0.060704  0.088419  0.061936  ... -0.070388  0.34692  0.213570  0.512390   \n",
       "2  0.027089  0.101260  0.035861  ...  0.118980  0.20484  0.068442  0.000578   \n",
       "3  0.016046  0.027189  0.014337  ... -0.047136  0.14082 -0.371070 -0.108130   \n",
       "4  0.034037  0.224500  0.018224  ... -0.035113 -0.42522  0.069521  0.263290   \n",
       "5  0.029561  0.038092  0.019897  ... -0.419130  0.50191 -0.670990  0.127950   \n",
       "6  0.015294  0.120970  0.014435  ...  0.259100  0.10333  0.048375 -0.349530   \n",
       "7  0.078086  0.105670  0.083278  ...  0.423170  0.17383  0.376420  0.072196   \n",
       "8  0.037149  0.032328  0.017056  ...  0.147890  0.29822 -0.105220  0.072432   \n",
       "9  0.005204  0.011072  0.008729  ...  0.028861 -0.10196 -0.334590  0.003074   \n",
       "\n",
       "      SKEW7     SKEW8     SKEW9    SKEW10  class  move  \n",
       "0 -1.401700 -0.536760  1.109600  0.280630      8    36  \n",
       "1 -0.089661 -0.120520  0.109120  0.409140      8     5  \n",
       "2  0.327350 -0.110150 -0.027281  0.118570      5     6  \n",
       "3  0.069448 -0.099661 -0.346300  0.237040      6    28  \n",
       "4  0.267010 -0.135760 -0.026827  0.323000      2    14  \n",
       "5 -0.144300 -0.395270  0.142920 -0.141420      7    20  \n",
       "6 -0.592230 -0.122360  0.261010  0.061718      2    30  \n",
       "7 -0.787140  0.065149 -0.273930  0.342480      8     5  \n",
       "8 -0.023623 -0.159720  0.139350 -0.192820      7    20  \n",
       "9  0.274650  0.192700 -0.106770  0.019649      3    39  \n",
       "\n",
       "[10 rows x 152 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df_r1[10].dtypes)\n",
    "df_r1[0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # just for visualization, not important\n",
    "# #Print class freq for each round of subject 1\n",
    "# target_dist=df_r1[0].groupby('class').size()\n",
    "# print(\"round1 class distribution\")\n",
    "# print(target_dist)\n",
    "\n",
    "# target_dist=df_r2[0].groupby('class').size()\n",
    "# print(\"round2 class distribution\")\n",
    "# print(target_dist)\n",
    "\n",
    "# target_dist=df_r3[0].groupby('class').size()\n",
    "# print(\"round3 class distribution\")\n",
    "# print(target_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1:\n",
      "round 1 whole dataset: (2887, 152)\n",
      "round 1 test dataset: (1155, 151)\n",
      "round 1 train dataset: (1732, 151)\n",
      "round 2 whole dataset: (2775, 152)\n",
      "round 2 test dataset: (1118, 151)\n",
      "round 2 train dataset: (1657, 151)\n",
      "round 3 whole dataset: (2498, 152)\n",
      "round 3 test dataset: (1024, 151)\n",
      "round 3 train dataset: (1474, 151)\n"
     ]
    }
   ],
   "source": [
    "# in each round for each movement we have almost 5 repetitions,\n",
    "# we keep 2/3 of repetitions for train and rest for test\n",
    "\n",
    "train_df_r1 = [pd.DataFrame(columns=cl_names)]*N_Subj\n",
    "test_df_r1 = [pd.DataFrame(columns=cl_names)]*N_Subj\n",
    "train_df_r2 = [pd.DataFrame(columns=cl_names)]*N_Subj\n",
    "test_df_r2 = [pd.DataFrame(columns=cl_names)]*N_Subj\n",
    "train_df_r3 = [pd.DataFrame(columns=cl_names)]*N_Subj\n",
    "test_df_r3 = [pd.DataFrame(columns=cl_names)]*N_Subj\n",
    "\n",
    "# 3 seperate for for the rounds:\n",
    "# round1:\n",
    "for s in range(0,N_Subj): # for each subject we do:\n",
    "    df = df_r1[s]\n",
    "    for i in range(1,9):\n",
    "        class_group = df.loc[df['class'] == i] # first we keep all the samples belonging to movement class number i\n",
    "        class_group.index = range(class_group.shape[0]) # how many samples are in class i (range)\n",
    "        target_dist = class_group.groupby(['move']).size() # how many times the movement i was repeated (it can be 5,4,3)\n",
    "        # this depends on if the subject performed a movemnt we eliminated it from database so some of movements instead of having 5 repetitions have less!\n",
    "        \n",
    "        mv_indx = target_dist.index\n",
    "        train_size = int((2/3)*len(mv_indx)) # 2/3 of number of repetitions is for training. e.g. if 5 times was repeated we keep 3 for training rest for test\n",
    "        train_mv = mv_indx[0:train_size]\n",
    "        for j in train_mv:\n",
    "            train_df_r1[s] = train_df_r1[s].append(class_group.loc[class_group['move'] == j], ignore_index=True)#adding to trainset 2/3 of repetitions of one movement\n",
    "        test_mv = mv_indx[train_size:]\n",
    "        for k in test_mv:\n",
    "            test_df_r1[s] = test_df_r1[s].append(class_group.loc[class_group['move'] == k], ignore_index=True)# adding to test set rest of the movement repetitions\n",
    "        \n",
    "    train_df_r1[s] = train_df_r1[s].astype(float)\n",
    "    train_df_r1[s]['class'] = train_df_r1[s]['class'].astype(int)\n",
    "    test_df_r1[s] = test_df_r1[s].astype(float)\n",
    "    test_df_r1[s]['class'] = test_df_r1[s]['class'].astype(int)\n",
    "    \n",
    "    #train and test set no longer need the 'move' column\n",
    "    train_df_r1[s].drop('move',inplace=True,axis=1) \n",
    "    test_df_r1[s].drop('move',inplace=True,axis=1)\n",
    "    \n",
    "print(\"Subject1:\")\n",
    "print(\"round 1 whole dataset:\",df_r1[0].shape)\n",
    "print(\"round 1 test dataset:\",test_df_r1[0].shape)\n",
    "print(\"round 1 train dataset:\",train_df_r1[0].shape)\n",
    "\n",
    "# round2:\n",
    "for s in range(0,N_Subj):\n",
    "    df = df_r2[s]\n",
    "    for i in range(1,9):\n",
    "        class_group = df.loc[df['class'] == i]\n",
    "        class_group.index = range(class_group.shape[0])\n",
    "        target_dist = class_group.groupby(['move']).size()\n",
    "        mv_indx = target_dist.index\n",
    "        train_size = int((2/3)*len(mv_indx))\n",
    "        train_mv = mv_indx[0:train_size]\n",
    "        for j in train_mv:\n",
    "            train_df_r2[s] = train_df_r2[s].append(class_group.loc[class_group['move'] == j], ignore_index=True)\n",
    "        test_mv = mv_indx[train_size:]\n",
    "        for k in test_mv:\n",
    "            test_df_r2[s] = test_df_r2[s].append(class_group.loc[class_group['move'] == k], ignore_index=True)\n",
    "        \n",
    "    train_df_r2[s] = train_df_r2[s].astype(float)\n",
    "    train_df_r2[s]['class'] = train_df_r2[s]['class'].astype(int)\n",
    "    test_df_r2[s] = test_df_r2[s].astype(float)\n",
    "    test_df_r2[s]['class'] = test_df_r2[s]['class'].astype(int)\n",
    "    train_df_r2[s].drop('move',inplace=True,axis=1)\n",
    "    test_df_r2[s].drop('move',inplace=True,axis=1)\n",
    "\n",
    "print(\"round 2 whole dataset:\",df_r2[0].shape)\n",
    "print(\"round 2 test dataset:\",test_df_r2[0].shape)\n",
    "print(\"round 2 train dataset:\",train_df_r2[0].shape)\n",
    "\n",
    "# round3:\n",
    "for s in range(0,N_Subj):\n",
    "    df = df_r3[s]\n",
    "    for i in range(1,9):\n",
    "        class_group = df.loc[df['class'] == i]\n",
    "        class_group.index = range(class_group.shape[0])\n",
    "        target_dist = class_group.groupby(['move']).size()\n",
    "        mv_indx = target_dist.index\n",
    "        train_size = int((2/3)*len(mv_indx))\n",
    "        train_mv = mv_indx[0:train_size]\n",
    "        for j in train_mv:\n",
    "            train_df_r3[s] = train_df_r3[s].append(class_group.loc[class_group['move'] == j], ignore_index=True)\n",
    "        test_mv = mv_indx[train_size:]\n",
    "        for k in test_mv:\n",
    "            test_df_r3[s] = test_df_r3[s].append(class_group.loc[class_group['move'] == k], ignore_index=True)\n",
    "        \n",
    "    train_df_r3[s] = train_df_r3[s].astype(float)\n",
    "    train_df_r3[s]['class'] = train_df_r3[s]['class'].astype(int)\n",
    "    test_df_r3[s] = test_df_r3[s].astype(float)\n",
    "    test_df_r3[s]['class'] = test_df_r3[s]['class'].astype(int)\n",
    "    train_df_r3[s].drop('move',inplace=True,axis=1)\n",
    "    test_df_r3[s].drop('move',inplace=True,axis=1)\n",
    "\n",
    "print(\"round 3 whole dataset:\",df_r3[0].shape)\n",
    "print(\"round 3 test dataset:\",test_df_r3[0].shape)\n",
    "print(\"round 3 train dataset:\",train_df_r3[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xbc78b38>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_r1[2].iloc[:, :10].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1:\n",
      "round1 train data: (1732, 151)\n",
      "round1 cleaned train data (1570, 151)\n",
      "round2 train data: (1657, 151)\n",
      "round2 cleaned train data (1490, 151)\n",
      "round3 train data: (1474, 151)\n",
      "round3 cleaned train data (1338, 151)\n"
     ]
    }
   ],
   "source": [
    "# outlier detection based on only two features: WL and MAV\n",
    "# cleaning train data\n",
    "train_df_r1_clean = [pd.DataFrame(columns=train_df_r1[0].columns)]*N_Subj\n",
    "train_df_r2_clean = [pd.DataFrame(columns=train_df_r1[0].columns)]*N_Subj\n",
    "train_df_r3_clean = [pd.DataFrame(columns=train_df_r1[0].columns)]*N_Subj\n",
    "\n",
    "#round 1:\n",
    "for s in range(0,N_Subj):\n",
    "    df = train_df_r1[s]\n",
    "    for i in range(1,9): #cleaning for each class of movement must be based only on the samples belonging to that class\n",
    "        class_group = df.loc[df['class'] == i]\n",
    "        mean = class_group.mean()\n",
    "        std = class_group.std()\n",
    "        x = 2.5 #threshold is considered 2.5 times of std\n",
    "        for j in range(1,11):\n",
    "            class_group = class_group[ np.abs(class_group['MAV'+str(j)] - mean['MAV'+str(j)]) <= x * std['MAV'+str(j)]]\n",
    "            class_group = class_group[ np.abs(class_group['WL'+str(j)] - mean['WL'+str(j)]) <= x * std['WL'+str(j)]]\n",
    "        train_df_r1_clean[s] = train_df_r1_clean[s].append(class_group, ignore_index=True)\n",
    "    train_df_r1_clean[s]['class'] = train_df_r1_clean[s]['class'].astype(int)\n",
    "    \n",
    "print(\"Subject1:\")\n",
    "print(\"round1 train data:\",train_df_r1[0].shape)\n",
    "print(\"round1 cleaned train data\",train_df_r1_clean[0].shape)\n",
    "\n",
    "#round 2:\n",
    "for s in range(0,N_Subj):\n",
    "    df = train_df_r2[s]\n",
    "    for i in range(1,9):\n",
    "        class_group = df.loc[df['class'] == i]\n",
    "        mean = class_group.mean()\n",
    "        std = class_group.std()\n",
    "        x = 2.5\n",
    "        for j in range(1,11):\n",
    "            class_group = class_group[ np.abs(class_group['MAV'+str(j)] - mean['MAV'+str(j)]) <= x * std['MAV'+str(j)] ]\n",
    "            class_group = class_group[ np.abs(class_group['WL'+str(j)] - mean['WL'+str(j)]) <= x * std['WL'+str(j)]]\n",
    "        train_df_r2_clean[s] = train_df_r2_clean[s].append(class_group, ignore_index=True)\n",
    "    train_df_r2_clean[s]['class'] = train_df_r2_clean[s]['class'].astype(int)\n",
    "    \n",
    "print(\"round2 train data:\",train_df_r2[0].shape)\n",
    "print(\"round2 cleaned train data\",train_df_r2_clean[0].shape)\n",
    "\n",
    "#round 3:\n",
    "for s in range(0,N_Subj):\n",
    "    df = train_df_r3[s]\n",
    "    for i in range(1,9):\n",
    "        class_group = df.loc[df['class'] == i]\n",
    "        mean = class_group.mean()\n",
    "        std = class_group.std()\n",
    "        x = 2.5\n",
    "        for j in range(1,11):\n",
    "            class_group = class_group[ np.abs(class_group['MAV'+str(j)] - mean['MAV'+str(j)]) <= x * std['MAV'+str(j)] ]\n",
    "            class_group = class_group[ np.abs(class_group['WL'+str(j)] - mean['WL'+str(j)]) <= x * std['WL'+str(j)]]\n",
    "        train_df_r3_clean[s] = train_df_r3_clean[s].append(class_group, ignore_index=True)\n",
    "    train_df_r3_clean[s]['class'] = train_df_r3_clean[s]['class'].astype(int)\n",
    "\n",
    "print(\"round3 train data:\",train_df_r3[0].shape)\n",
    "print(\"round3 cleaned train data\",train_df_r3_clean[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x145e0470>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_r1_clean[2].iloc[:, :10].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Visualize Class Counts\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.style.use('ggplot')\n",
    "# sns.countplot(y=train_df_r1_clean[0].iloc[:,-1] ,data=train_df_r1_clean[0].iloc[:,0:-1])\n",
    "# plt.xlabel(\"count of each class\")\n",
    "# plt.ylabel(\"classes\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch = list(range(0,10))+[150]\n",
    "# ch_s = train_df_r1[0].iloc[:, Ch]\n",
    "# plt.figure(figsize = (9,9))\n",
    "# sns.heatmap(data=ch_s.corr().round(2), cmap='coolwarm', linewidths=.2, annot=True, annot_kws={\"size\":12})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the correlation between features, we perform this step, from this the CB featureset was chosen\n",
    "# keep_ind = [4,14,24,34,44,54,64,74,84,94,104,114,124,134,144]\n",
    "# droped = train_df_r1[0].iloc[:, keep_ind]\n",
    "# plt.figure(figsize = (9,9))\n",
    "# sns.heatmap(data=droped.corr().round(2), cmap='coolwarm', linewidths=.2, annot=True, annot_kws={\"size\":12})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: MAV, ZC, SSC, WL, HP-A, HP-M, HP-C, SE, CCI, CCII, CCIII, CCIV, RMS, IEMG, SKEW\n",
    "TD = list(range(0,40)) #MAV,ZC,SSC,WL\n",
    "ITD = list(range(0,70))+list(range(120,140)) #MAV, ZC, SSC, WL, HP-A, HP-M, HP-C,RMS,IEMG\n",
    "CB = list(range(10,40)) + list(range(50,90)) #ZC, SSC, WL, HP_M. HP_C, ,SE, CC1 \n",
    "full = list(range(0,150))\n",
    "\n",
    "Samp_pipline = list(range(30,40))+list(range(70,90))+list(range(120,130)) #WL,SE,CCI,IEMG\n",
    "HP = list(range(40,70))\n",
    "good = list(range(30,40)) + list(range(50,70))\n",
    "opt = list(range(30,40)) + list(range(50,70)) + list(range(80,90)) #WL, HP-M, HP-C, CCI\n",
    "full_skew = list(range(0,140))\n",
    "\n",
    "\n",
    "f_set = ITD # this should be changed when you want to use different feature set (and following cells must be executed again)\n",
    "f_name = \"full\" # this will be used if you want to save the scaler model and trained model for future used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X and Y seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject1:\n",
      "train cleaned: (1570, 90) test (1155, 90)\n",
      "train not cleaned: (1732, 90)\n"
     ]
    }
   ],
   "source": [
    "# after changing feature set this cell and following ones must be executed again\n",
    "#extract x and y for training and testing sets\n",
    "X_train_r1 = [0]*N_Subj\n",
    "X_train_r2 = [0]*N_Subj\n",
    "X_train_r3 = [0]*N_Subj\n",
    "\n",
    "y_train_r1 = [0]*N_Subj\n",
    "y_train_r2 = [0]*N_Subj\n",
    "y_train_r3 = [0]*N_Subj\n",
    "\n",
    "X_test_r1 = [0]*N_Subj\n",
    "X_test_r2 = [0]*N_Subj\n",
    "X_test_r3 = [0]*N_Subj\n",
    "\n",
    "y_test_r1 = [0]*N_Subj\n",
    "y_test_r2 = [0]*N_Subj\n",
    "y_test_r3 = [0]*N_Subj\n",
    "\n",
    "for s in range(0,N_Subj):\n",
    "    X_train_r1[s] = train_df_r1_clean[s].iloc[:,f_set]\n",
    "    X_train_r2[s] = train_df_r2_clean[s].iloc[:,f_set]\n",
    "    X_train_r3[s] = train_df_r3_clean[s].iloc[:,f_set]\n",
    "    y_train_r1[s] = train_df_r1_clean[s].iloc[:,-1]\n",
    "    y_train_r2[s] = train_df_r2_clean[s].iloc[:,-1]\n",
    "    y_train_r3[s] = train_df_r3_clean[s].iloc[:,-1]\n",
    "    \n",
    "    X_test_r1[s] = test_df_r1[s].iloc[:,f_set]\n",
    "    y_test_r1[s] = test_df_r1[s].iloc[:,-1]\n",
    "    y_test_r1[s] = y_test_r1[s].astype(int)\n",
    "    X_test_r2[s] = test_df_r2[s].iloc[:,f_set]\n",
    "    y_test_r2[s] = test_df_r2[s].iloc[:,-1]\n",
    "    y_test_r2[s] = y_test_r2[s].astype(int)\n",
    "    X_test_r3[s] = test_df_r3[s].iloc[:,f_set]\n",
    "    y_test_r3[s] = test_df_r3[s].iloc[:,-1]\n",
    "    y_test_r3[s] = y_test_r3[s].astype(int)\n",
    "\n",
    "print(\"Subject1:\")\n",
    "print(\"train cleaned:\",X_train_r1[0].shape,\"test\",X_test_r1[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatinating the rounds for train and test\n",
    "X_train = [0]*N_Subj\n",
    "y_train = [0]*N_Subj\n",
    "\n",
    "X_test = [0]*N_Subj\n",
    "y_test = [0]*N_Subj\n",
    "\n",
    "for s in range(0,N_Subj):\n",
    "    X_train[s] = pd.concat([X_train_r1[s], X_train_r2[s], X_train_r3[s]], ignore_index=True)\n",
    "    y_train[s] = pd.concat([y_train_r1[s], y_train_r2[s], y_train_r3[s]], ignore_index=True)\n",
    "    \n",
    "    X_test[s] = pd.concat([X_test_r1[s], X_test_r2[s], X_test_r3[s]], ignore_index=True)\n",
    "    y_test[s] = pd.concat([y_test_r1[s], y_test_r2[s], y_test_r3[s]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler fitted on train is used on both train and test\n",
    "\n",
    "for s in range(0,N_Subj):\n",
    "    scaler=StandardScaler(copy=False).fit(X_train[s])\n",
    "    scaler.transform(X_train[s])\n",
    "    scaler.transform(X_test[s])\n",
    "    \n",
    "    # save the scaler for feature use on new unseen data if you don't want to fit the scaler from beginning again\n",
    "#     pickle.dump(scaler, open(f_name+'_s'+str(s+1)+'_scaler.pkl', 'wb'))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shuffle X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full test label shape : (3297,)\n",
      "full test label shape : (3229,)\n",
      "full test label shape : (3280,)\n",
      "full test label shape : (3073,)\n",
      "full test label shape : (3324,)\n",
      "full test label shape : (3308,)\n",
      "full test label shape : (3273,)\n",
      "full test label shape : (3041,)\n",
      "full test label shape : (3174,)\n",
      "full test label shape : (3294,)\n",
      "full test label shape : (3254,)\n"
     ]
    }
   ],
   "source": [
    "# for some algorithms (e.g. perceptron) shuffling the samples is very important\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "for i in range(N_Subj):\n",
    "    X_train[i] , y_train[i] = shuffle(X_train[i],y_train[i])\n",
    "    X_test[i] , y_test[i] = shuffle(X_test[i],y_test[i])\n",
    "    print(\"full test label shape : \" + str(y_test[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "#### not usefull for our purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PCA fit\n",
    "# from sklearn.decomposition import PCA\n",
    "# # based on explained cumulative variance\n",
    "# pca = PCA(n_components=0.95,svd_solver='full') \n",
    "# pca.fit(X_train)\n",
    "# pca.n_components_ \n",
    "# x_pca = pca.transform(X_train)\n",
    "# print(\"Dataset shape before PCA: \", X_train.shape)\n",
    "# print(\"Dataset shape after PCA: \", x_pca.shape)#19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_x_pca = pca.transform(X_test)\n",
    "# print(\"Dataset shape before PCA: \", X_test.shape)\n",
    "# print(\"Dataset shape after PCA: \", t_x_pca.shape)#19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #VISUALIZE The cumulative percentage of explained variance\n",
    "# cum_explained_var=np.cumsum(pca.explained_variance_ratio_)\n",
    "# pd.DataFrame(cum_explained_var).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = sns.barplot( data=explained_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_Df = pd.DataFrame(data = x_pca\n",
    "#              , columns = ['pc1', 'pc2','pc3','pc4','pc5', 'pc6','pc7','pc8','pc9','pc10',\n",
    "#                          'pc11', 'pc12','pc13','pc14','pc15', 'pc16','pc17','pc18','pc19'])\n",
    "# pca_Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(pca.components_,index=['pc1', 'pc2','pc3','pc4','pc5', 'pc6','pc7','pc8','pc9','pc10',\n",
    "#                          'pc11', 'pc12','pc13','pc14'],columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject: 1 accuracy:  96.26933575978161\n",
      "subject: 2 accuracy:  93.46546918550635\n",
      "subject: 3 accuracy:  84.60365853658537\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-cd84680ee934>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#,weights='distance') #for sbj3 with 9 nn 0.93 train accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#     knn.fit(X_train_lda[s], y_train_lda[s]) #train and test with outlier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#     y_pred = knn.predict(X_test_lda[s])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 delayed_query(\n\u001b[0;32m    453\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 454\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m             )\n\u001b[0;32m    456\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, data, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[1;32m--> 291\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "knn_acc = [0]*N_Subj\n",
    "for s in range(0,N_Subj):\n",
    "    knn = KNeighborsClassifier(n_neighbors=40)#,weights='distance')\n",
    "    knn.fit(X_train[s],y_train[s])\n",
    "    y_pred = knn.predict(X_test[s])\n",
    "    \n",
    "    knn_acc[s]=metrics.accuracy_score(y_test[s], y_pred)\n",
    "    print('subject:',s+1,\"accuracy: \", knn_acc[s]*100)\n",
    "sns.heatmap(confusion_matrix(y_test[10], y_pred), annot=True, fmt='d', cmap=\"Blues\"); \n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "print(np.mean(knn_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search for KNN\n",
    "# Knn_acc = [0]*N_Subj\n",
    "# for s in range(0,N_Subj):\n",
    "#     classifier = KNeighborsClassifier()\n",
    "#     parameters = {'n_neighbors':np.arange(50,52)}\n",
    "#     gs = GridSearchCV(classifier, parameters, cv=3, scoring = 'accuracy', verbose=10, n_jobs=-1)\n",
    "#     gs = gs.fit(X_train[s], y_train[s])\n",
    "\n",
    "#     #summarize the results of your GRIDSEARCH\n",
    "#     print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "# #     means = gs.cv_results_['mean_test_score']\n",
    "# #     stds = gs.cv_results_['std_test_score']\n",
    "# #     params = gs.cv_results_['params']\n",
    "# #     for mean, stdev, param in zip(means, stds, params):\n",
    "# #         print(\"Mean %f Std (%f) with: %r\" % (mean, stdev, param))\n",
    "#     best_model = gs.best_estimator_\n",
    "#     y_pred = best_model.predict(X_test[s])\n",
    "#     Knn_acc[s]=metrics.accuracy_score(y_test[s], y_pred)\n",
    "#     print(\"subject:\",s+1,\"accuracy: \", Knn_acc[s])\n",
    "# # sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap=\"Blues\"); \n",
    "# # plt.ylabel('True Label')\n",
    "# # plt.xlabel('Predicted Label')\n",
    "# print(Knn_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_acc = [0]*N_Subj\n",
    "for s in range(0,N_Subj):\n",
    "    model = SVC(kernel='linear',C=1, class_weight=\"balanced\",gamma = 'auto')\n",
    "    model.fit(X_train[s], y_train[s])\n",
    "    y_pred = model.predict(X_test[s])\n",
    "    \n",
    "    # save the model to disk\n",
    "#     filename = 'SVM_'+f_name+'_s'+str(s+1)+'.sav'\n",
    "#     pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    SVM_acc[s] = metrics.accuracy_score(y_test[s], y_pred)\n",
    "    print(\"subject\",s+1,'accuracy:',SVM_acc[s]*100)\n",
    "sns.heatmap(confusion_matrix(y_test[10], y_pred), annot=True, fmt='d', cmap=\"Blues\", cbar=False);\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "print(np.mean(SVM_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search for SVM\n",
    "# SVC_acc=[0]*N_Subj\n",
    "# classifier = SVC()\n",
    "# parameters = {\"kernel\":['linear'], \"C\":[1,10,100,1000],\"gamma\":[1e-4]} \n",
    "# for s in range(0,N_Subj):\n",
    "#     gs = GridSearchCV(classifier, parameters, cv=3, scoring = 'accuracy', verbose=50, n_jobs=-1, refit=True)\n",
    "#     gs = gs.fit(X_train[s], y_train[s])\n",
    "#     #summarize the results of your GRIDSEARCH\n",
    "#     print('***GRIDSEARCH RESULTS***')\n",
    "#     print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "#     best_model = gs.best_estimator_\n",
    "#     y_pred = best_model.predict(X_test[s])\n",
    "#     SVC_acc[s] = metrics.accuracy_score(y_test[s], y_pred)\n",
    "#     print(\"subject\",s+1,\"accuracy\",SVC_acc[s])\n",
    "# print(SVC_acc[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test[s], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_acc=[0]*N_Subj\n",
    "for s in range(0,N_Subj): \n",
    "    model = GaussianNB(var_smoothing=0.1)\n",
    "\n",
    "    model.fit(X_train[s], y_train[s])\n",
    "    y_pred=model.predict(X_test[s])\n",
    "    NB_acc[s] = metrics.accuracy_score(y_test[s], y_pred)\n",
    "    print(\"subject:\",s+1,\"accuracy: \", NB_acc[s]*100)\n",
    "sns.heatmap(confusion_matrix(y_test[10], y_pred), annot=True, fmt='d', cmap=\"Blues\", cbar=False);\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search for NB\n",
    "# NB = GaussianNB()\n",
    "# l1=[0.125, 0.125,0.125,0.125,0.125, 0.125,0.125,0.125]\n",
    "# parameters = {'priors':[l1,None]}\n",
    "\n",
    "# NB_acc=[0]*N_Subj\n",
    "# for s in range(0,N_Subj): \n",
    "#     gs = GridSearchCV(NB, parameters, cv=3, scoring = 'accuracy', verbose=50, n_jobs=-1, refit=True)\n",
    "#     gs = gs.fit(X_train[s], y_train[s])\n",
    "\n",
    "#     print('***GRIDSEARCH RESULTS***')\n",
    "#     print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "#     best_model = gs.best_estimator_\n",
    "#     y_pred = best_model.predict(X_test[s])\n",
    "#     NB_acc[s] = metrics.accuracy_score(y_test[s], y_pred)\n",
    "#     print(\"subject\",s+1,\"accuracy: \", NB_acc[s])\n",
    "# print(NB_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_acc=[0]*N_Subj\n",
    "\n",
    "LDA = LinearDiscriminantAnalysis(solver='svd')\n",
    "for s in range(0,N_Subj):\n",
    "    LDA.fit(X_train[s], y_train[s])\n",
    "    \n",
    "#     # save the model to disk\n",
    "#     filename = 'LDA_'+f_name+'_s'+str(s+1)+'.sav'\n",
    "#     pickle.dump(LDA, open(filename, 'wb'))\n",
    "    \n",
    "    y_pred = LDA.predict(X_test[s])\n",
    "    LDA_acc[s] = metrics.accuracy_score(y_test[s], y_pred)\n",
    "\n",
    "    print(\"subject\",s+1,\"accuracy: \", LDA_acc[s]*100)\n",
    "sns.heatmap(confusion_matrix(y_test[10], y_pred), annot=True, fmt='d', cmap=\"Reds\");\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "print(np.mean(LDA_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search for LDA\n",
    "# LDA = LinearDiscriminantAnalysis()\n",
    "# parameters = {'solver':['svd','lsqr']}\n",
    "# LDA_acc=[0]*N_Subj\n",
    "\n",
    "# for s in range(0,N_Subj):\n",
    "#     gs = GridSearchCV(LDA, parameters, cv=3, scoring = 'accuracy', verbose=50, n_jobs=-1, refit=True)\n",
    "#     gs = gs.fit(X_train[s], y_train[s])\n",
    "\n",
    "#     print('***GRIDSEARCH RESULTS***')\n",
    "#     print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "\n",
    "#     best_model = gs.best_estimator_\n",
    "#     y_pred = best_model.predict(X_test[s])\n",
    "#     LDA_acc[s] = metrics.accuracy_score(y_test[s], y_pred)\n",
    "#     print(\"subject\",s+1,\"accuracy: \", LDA_acc[s])\n",
    "# print(LDA_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************subject: 1 average accuracy:*********** 95.32302092811646\n",
      "************subject: 2 average accuracy:*********** 93.52895633323008\n",
      "************subject: 3 average accuracy:*********** 87.96951219512195\n",
      "************subject: 4 average accuracy:*********** 89.54604620891638\n",
      "************subject: 5 average accuracy:*********** 90.17599277978337\n",
      "************subject: 6 average accuracy:*********** 91.24395405078596\n",
      "************subject: 7 average accuracy:*********** 85.92117323556371\n",
      "************subject: 8 average accuracy:*********** 93.83755343636962\n",
      "************subject: 9 average accuracy:*********** 91.99590422180212\n",
      "************subject: 10 average accuracy:*********** 95.3217972070431\n",
      "************subject: 11 average accuracy:*********** 91.100184388445\n",
      "[[0.9523809523809523, 0.9526842584167425, 0.9520776463451622, 0.9526842584167425, 0.9523809523809523, 0.9599636032757052, 0.9511677282377919, 0.951471034273582, 0.9526842584167425, 0.9557173187746436, 0.951471034273582, 0.951471034273582, 0.9511677282377919, 0.9502578101304215, 0.9551107067030634, 0.9572338489535942, 0.9578404610251744, 0.9496511980588414, 0.954200788595693, 0.9529875644525326], [0.9352740786621245, 0.9386807061009601, 0.938061319293899, 0.935583772065655, 0.931248064416228, 0.933106224837411, 0.9321771446268194, 0.9315577578197585, 0.9287705171879839, 0.9377516258903685, 0.9383710126974295, 0.933725611644472, 0.9411582533292041, 0.9389903995044906, 0.931248064416228, 0.9365128522762465, 0.9352740786621245, 0.9365128522762465, 0.940538866522143, 0.931248064416228], [0.8795731707317073, 0.8804878048780488, 0.8792682926829268, 0.8801829268292682, 0.8798780487804878, 0.8783536585365853, 0.875, 0.8807926829268292, 0.8801829268292682, 0.8804878048780488, 0.8798780487804878, 0.8774390243902439, 0.8817073170731707, 0.8798780487804878, 0.8786585365853659, 0.8795731707317073, 0.8798780487804878, 0.8820121951219512, 0.8789634146341463, 0.8817073170731707], [0.8948909860071591, 0.8987959648551904, 0.8952164009111617, 0.8948909860071591, 0.8987959648551904, 0.8955418158151643, 0.9049788480312398, 0.8922876667751383, 0.8935893263911487, 0.8913114220631305, 0.8984705499511878, 0.8984705499511878, 0.8942401561991539, 0.8952164009111617, 0.8935893263911487, 0.8952164009111617, 0.8932639114871461, 0.8978197201431826, 0.8909860071591279, 0.8916368369671331], [0.8992178098676293, 0.9019253910950662, 0.9007220216606499, 0.8998194945848376, 0.8965102286401926, 0.9046329723225031, 0.9043321299638989, 0.9016245487364621, 0.9022262334536703, 0.8992178098676293, 0.9007220216606499, 0.9061371841155235, 0.9055354993983152, 0.9001203369434416, 0.9034296028880866, 0.8992178098676293, 0.8998194945848376, 0.9004211793020457, 0.9070397111913358, 0.9025270758122743], [0.9153567110036276, 0.9126360338573156, 0.910217654171705, 0.9126360338573156, 0.914752116082225, 0.9138452237001209, 0.909310761789601, 0.9144498186215235, 0.9111245465538089, 0.912031438935913, 0.9135429262394196, 0.9159613059250302, 0.9135429262394196, 0.9114268440145102, 0.9117291414752116, 0.9114268440145102, 0.9099153567110037, 0.910217654171705, 0.9126360338573156, 0.912031438935913], [0.8585395661472655, 0.8545676749159792, 0.8579285059578369, 0.8560953253895509, 0.8597616865261228, 0.8652612282309807, 0.8576229758631225, 0.8588450962419798, 0.8585395661472655, 0.8603727467155515, 0.8585395661472655, 0.8606782768102658, 0.8606782768102658, 0.8576229758631225, 0.8579285059578369, 0.8619003971891231, 0.8631225175679804, 0.8567063855789795, 0.8622059272838375, 0.8573174457684082], [0.9414666228214403, 0.9358763564616902, 0.9394935876356462, 0.9394935876356462, 0.9414666228214403, 0.9388359092403814, 0.942124301216705, 0.937520552449852, 0.9414666228214403, 0.9316014468924696, 0.937520552449852, 0.9414666228214403, 0.9362051956593226, 0.9394935876356462, 0.9381782308451168, 0.9345609996711608, 0.9355475172640578, 0.9368628740545873, 0.9385070700427491, 0.9398224268332785], [0.9212350346565847, 0.921865154379332, 0.9180844360428482, 0.9190296156269692, 0.9221802142407057, 0.9183994959042218, 0.922810333963453, 0.9174543163201008, 0.9161940768746062, 0.9240705734089477, 0.9224952741020794, 0.921865154379332, 0.9171392564587272, 0.9174543163201008, 0.9224952741020794, 0.9202898550724637, 0.9193446754883428, 0.920919974795211, 0.9174543163201008, 0.9183994959042218], [0.9511232544019429, 0.9559805707346691, 0.9529447480267152, 0.9562841530054644, 0.9523375834851244, 0.9450516089860352, 0.9581056466302368, 0.9532483302975107, 0.9517304189435337, 0.9529447480267152, 0.9480874316939891, 0.9523375834851244, 0.9544626593806922, 0.9623557984213722, 0.9471766848816029, 0.9526411657559198, 0.953551912568306, 0.9532483302975107, 0.9541590771098968, 0.9565877352762598], [0.9145666871542717, 0.9170251997541488, 0.9124154886293793, 0.9154886293792256, 0.9093423478795328, 0.91180086047941, 0.9044253226797787, 0.9053472649047326, 0.907498463429625, 0.9124154886293793, 0.9096496619545175, 0.9081130915795943, 0.9102642901044868, 0.9102642901044868, 0.9127228027043639, 0.9139520590043024, 0.9142593730792871, 0.91180086047941, 0.9096496619545175, 0.9090350338045482]]\n"
     ]
    }
   ],
   "source": [
    "MLP_acc = []\n",
    "\n",
    "av_for = 20 # MLP is stochastic so it should be averaged over some number of repetitions\n",
    "\n",
    "MLP=MLPClassifier(hidden_layer_sizes=(300), #warm_start=True,\n",
    "              activation='tanh', alpha=0.0001, n_iter_no_change=20, solver='sgd',tol=0.0001,\n",
    "              max_iter=1000, verbose=False) \n",
    "\n",
    "for s in range(0,N_Subj):\n",
    "    acc_list =[]\n",
    "    for i in range(av_for):\n",
    "        MLP.fit(X_train[s], y_train[s])\n",
    "        y_pred = MLP.predict(X_test[s])\n",
    "        \n",
    "        acc_list.append(metrics.accuracy_score(y_test[s], y_pred)) \n",
    "#     print(acc_list)\n",
    "    aver=np.mean(acc_list)\n",
    "    MLP_acc.append(acc_list)\n",
    "    print(\"************subject:\",s+1,\"average accuracy:***********\", aver*100)\n",
    "print(MLP_acc)\n",
    "# print(np.mean(MLP_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.11\n",
      "95.6\n",
      "95.29\n",
      "95.63\n",
      "95.23\n",
      "94.51\n",
      "95.81\n",
      "95.32\n",
      "95.17\n",
      "95.29\n",
      "94.81\n",
      "95.23\n",
      "95.45\n",
      "96.24\n",
      "94.72\n",
      "95.26\n",
      "95.36\n",
      "95.32\n",
      "95.42\n",
      "95.66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9532302092811646"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in MLP_acc[9]:\n",
    "    print(round(i*100,2))\n",
    "np.mean(MLP_acc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_test[10], y_pred), annot=True, fmt='d', cmap=\"Reds\");\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search for SVM\n",
    "# classifier = MLPClassifier()\n",
    "# parameters = {\"hidden_layer_sizes\":[(50,20)],  \"max_iter\": [1000], \"alpha\": [0.001],\"activation\":['relu'],'solver':['adam']}\n",
    "# # activation : {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}\n",
    "# acc_list=[0]*5\n",
    "# MLP_acc = [0]*N_Subj\n",
    "\n",
    "# for s in range(0,N_Subj):\n",
    "#     for i in range(5):\n",
    "#         gs = GridSearchCV(classifier, parameters, cv=3, scoring = 'accuracy', verbose=50, n_jobs=-1, refit=True)\n",
    "#         gs = gs.fit(X_train[s], y_train[s])\n",
    "\n",
    "#         print('***GRIDSEARCH RESULTS***')\n",
    "#         print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "#         means = gs.cv_results_['mean_test_score']\n",
    "#         stds = gs.cv_results_['std_test_score']\n",
    "#         params = gs.cv_results_['params']\n",
    "\n",
    "#         for mean, stdev, param in zip(means, stds, params):\n",
    "#             print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#         best_model = gs.best_estimator_\n",
    "#         y_pred = best_model.predict(X_test[s])\n",
    "#         acc_list[i] = metrics.accuracy_score(y_test[s], y_pred)\n",
    "#         print(acc_list[i])\n",
    "#     aver=np.mean(acc_list)\n",
    "#     MLP_acc[s]=aver\n",
    "#     print('********************************************')\n",
    "#     print(\"subject:\",s+1)\n",
    "#     print(\"average accuracy:\", aver)\n",
    "\n",
    "# print(\"MLP accuracy: \", MLP_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
