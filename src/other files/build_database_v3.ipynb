{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7WjYz9Qylrm"
   },
   "source": [
    "##Mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "id": "TbGfHQQDx0_D",
    "outputId": "fba95f6f-0d66-4e01-cf5c-d680a7c2df33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "root = '/content/gdrive'\n",
    "drive.mount(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TErSSS8yyGl"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "EunpxPI8yxib",
    "outputId": "6c3ac25f-de96-4d0d-be08-bc475622a520"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#%tensorflow_version 1.x\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import sys, os, os.path\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "#import kapre\n",
    "import keras\n",
    "import keras.utils as ku\n",
    "\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Flatten, Dense, LeakyReLU, PReLU, LocallyConnected2D\n",
    "from keras.layers import BatchNormalization, UpSampling2D, Activation, Dropout, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.initializers import RandomNormal\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkKfd_stzJ0t"
   },
   "source": [
    "#Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "id": "kChCErd0zS3P",
    "outputId": "6d6ce98b-9566-4b4c-f4d7-0ecd14742952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data base Shape (1, 3)\n",
      "subject 1 database shape (2901, 5122)\n"
     ]
    }
   ],
   "source": [
    "# Database [subject][round] 2D np array\n",
    "# \n",
    "database = []\n",
    "# change the path to the directory csv files of each subject are saved\n",
    "path = 'C:\\\\Users\\\\noemi\\\\Desktop\\\\university\\\\university\\\\tesi\\\\Thesis-XAI\\\\resources\\data_deep\\deep_V3_noshuffle\\Deep learning database_V3_session 2' \n",
    "\n",
    "# loading subject 1-11 session 1\n",
    "for subject in range(8,9):\n",
    "  temp_database = []\n",
    "  for r in range(1,4):\n",
    "    df = pd.read_csv(path+'/deep_database_v3_sbj'+str(subject)+'_s2_WL512_S128_r'+str(r)+'.csv')\n",
    "    temp_database.append(np.array(df))\n",
    "  database.append(temp_database)\n",
    "\n",
    "\n",
    "print('Data base Shape', np.shape(database))\n",
    "print('subject 1 database shape', database[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hgxpZINLJf4X",
    "outputId": "677a5190-999d-44a8-eb45-7102e8cdeead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1 database shape 6.0\n"
     ]
    }
   ],
   "source": [
    "print('subject 1 database shape', database[0][0][0,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "tiBgcPKV_C01",
    "outputId": "07ab27e9-fd1c-4c43-99f7-617ea718b86c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data base Shape (1, 3)\n",
      "subject 1 database shape (2901, 10, 512)\n",
      "lable Shape (1, 3)\n",
      "subject 1 lable shape (2901,)\n",
      "move Shape (1, 3)\n",
      "subject 1 move shape (2901,)\n"
     ]
    }
   ],
   "source": [
    "# change this to the directory the reformed database needs to be saved\n",
    "path = 'C:\\\\Users\\\\noemi\\\\Desktop\\\\university\\\\university\\\\tesi\\\\Thesis-XAI\\\\resources\\\\data_deep\\\\deep_V3_noshuffle\\\\'\n",
    "# reforming database\n",
    "# dataset [subject][round]np.array[sample number,channels,time]\n",
    "# label [subject][round]np.array[sample number]\n",
    "# move [subject][round]np.array[sample number]\n",
    "dataset = []\n",
    "label = []\n",
    "move = []\n",
    "\n",
    "for subject in range(1):\n",
    "  round_database = []\n",
    "  round_label = []\n",
    "  round_move = []\n",
    "  for r in range(3):\n",
    "    round_database.append(database[subject][r][:,:-2].reshape(database[subject][r].shape[0],10,512))\n",
    "    round_label.append(database[subject][r][:,-2])\n",
    "    round_move.append(database[subject][r][:,-1])\n",
    "  dataset.append(round_database)\n",
    "  label.append(round_label)\n",
    "  move.append(round_move)\n",
    "\n",
    "print('Data base Shape', np.shape(dataset))\n",
    "print('subject 1 database shape', dataset[0][0].shape)\n",
    "\n",
    "print('lable Shape', np.shape(label))\n",
    "print('subject 1 lable shape', label[0][0].shape)\n",
    "\n",
    "print('move Shape', np.shape(move))\n",
    "print('subject 1 move shape', move[0][0].shape)\n",
    "\n",
    "# save data \n",
    "np.save(path+'final_dataset_V3_sess2_8',dataset)\n",
    "np.save(path+'final_label_V3_sess2_8',label)\n",
    "np.save(path+'final_move_V3_sess2_8',move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "pkKfd_stzJ0t"
   ],
   "machine_shape": "hm",
   "name": "build database v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
